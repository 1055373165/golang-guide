- [https://www.topgoer.com/Go%E9%AB%98%E7%BA%A7/](https://www.topgoer.com/Go高级/)
- https://www.topgoer.cn/docs/goalgorithm/goalgorithm-1cm6akian87vb
- go算法模板：https://greyireland.gitbook.io/algorithm-pattern/
- Github: https://github.com/hunterhug

# [速查表](https://blog.csdn.net/itcodexy/article/details/109575269?app_version=5.8.0&csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"109575269"%2C"source"%3A"qq_45696377"}&utm_source=app)

## 图例

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837333294-8cc3292f-4ca1-4b42-a94a-cc4b44c994a5.png)

## 数据结构复杂度

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837000334-b5cda454-f57c-49f0-a4cc-c215ec522d12.png)

## 排序算法复杂度-数组

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837027297-21d925d5-00a5-4cd7-872b-366c33b243c6.png)

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671463999425-4f04dbde-e896-4575-a5a1-a9c4b93e498f.png)

## 图操作

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837084309-6d0dbcef-3a87-448a-937a-f511fa9e8b4e.png)

## 堆操作

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837277221-93bfde32-8f4a-468a-a2a1-5b80748748e4.png)



## 大-O复杂度曲线

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837138054-7d3aa252-902c-45ab-87ea-076df0c1138b.png)

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1663837188150-fd031911-be6a-4f4f-b42c-a7a22dc61267.png)

# 数据结构

## Q1：链表，队列和栈的区别 

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1662348730108-fb8ddbb0-b395-4e57-802c-e85476e5146e.png)



- **链表**是一种物理存储单元上非连续的一种数据结构，看名字我们就知道他是一种链式的结构，就像一群人手牵着手一样。链表有单向的，双向的，还有环形的。
- **队列**是一种特殊的线性表，他的特殊性在于我们只能操作他头部和尾部的元素，中间的元素我们操作不了，我们只能在他的头部进行删除，尾部进行添加。就像大家排队到银行取钱一样，先来的肯定要排到前面，后来的只能排在队尾，所有元素都要遵守这个操作，没有VIP会员，所以走后门插队的现象是不可能存在的，他是一种先进先出的数据结构。我们来看一下队列的数据结构是什么样的。
- **栈**也是一种特殊的线性表，他只能对栈顶进行添加和删除元素。栈有入栈和出栈两种操作，他就好像我们把书一本本的摞起来，最先放的书肯定是摞在下边，最后放的书肯定是摞在了最上面，摞的时候不允许从中间放进去，拿书的时候也是先从最上面开始拿，不允许从下边或中间抽出来。

## Q2:二叉树中完全二叉树、满二叉树、二叉排序树、平衡二叉树的区别和联系

### 1、完全二叉树：

只有最下面的两层结点度小于2，并且最下面一层的结点都集中在该层最左边的若干位置。

### 2、满二叉树：

是一颗完全二叉树；

除了叶结点外每一个结点都有左右子叶且叶结点都处在最底层。深度为k，且有2的(k)次方－1个节点。

### 3、堆：

是一颗完全二叉树；

大根堆：左右子树的结点值都小于根结点值，左右子树都是大根堆。

小根堆：左右子树的结点值都大于根结点值，左右子树都是小根堆。

### 4、[二叉排序树（二叉查找树）](https://www.topgoer.com/Go高级/二叉搜索树.html)及代码实现:

左子树上的值都小于根结点的值，右子树上的值都大于根结点得值，左右子树都是二叉排序树。

### 5、平衡二叉树（ALV）：

是一颗二叉排序树；

左子树和右子树的差值不超过1，左右子树都为平衡二叉树。

常用算法有红黑树、AVL、Treap

## Q5：什么是 AVL 树？

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1662348730387-6e2c3794-187b-4c7d-8f97-27850a7bbe25.png)



**AVL 树** 是平衡⼆叉查找树，增加和删除节点后通过树形旋转重新达到平衡。右旋是以某个节点为中⼼， 将它沉⼊当前右⼦节点的位置，⽽让当前的左⼦节点作为新树的根节点，也称为顺时针旋转。同理左旋 是以某个节点为中⼼，将它沉⼊当前左⼦节点的位置，⽽让当前的右⼦节点作为新树的根节点，也称为 逆时针旋转。



## Q6：什么是红⿊树？



红⿊树 是 1972 年发明的，称为对称⼆叉 B 树，1978 年正式命名红⿊树。主要特征是在每个节点上增加⼀个属性表示节点颜⾊，可以红⾊或⿊⾊。





![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1662348730546-f3de5e10-20eb-44b5-823f-e5237bd974c4.png)



红⿊树和 AVL 树 类似，都是在进⾏插⼊和删除时通过旋转保持⾃身平衡，从⽽获得较⾼的查找性能。与 AVL 树 相⽐，红⿊树不追求所有递归⼦树的⾼度差不超过 1，保证从根节点到叶尾的最⻓路径不超过最短路径的 2 倍，所以最差时间复杂度是 O(logn)。

红⿊树通过重新着⾊和左右旋转，更加⾼效地完成了插⼊和删除之后的⾃平衡调整。红⿊树在本质上还是⼆叉查找树，它额外引⼊了 5 个约束条件： ① 节点只能是红⾊或⿊⾊。 ② 根节点必须是⿊⾊。 ③ 所有 NIL 节点都是⿊⾊的。 ④ ⼀条路径上不能出现相邻的两个红⾊节点。 ⑤ 在任何递归⼦树中，根节点到叶⼦节点的所有路径上包含相同数⽬的⿊⾊节点。

这五个约束条件保证了红⿊树的新增、删除、查找的最坏时间复杂度均为 O(logn)。如果⼀个树的左⼦节点或右⼦节点不存在，则均认定为⿊⾊。红⿊树的任何旋转在 3 次之内均可完成。



## Q7：AVL 树和红⿊树的区别？

红⿊树的平衡性不如 AVL 树，它维持的只是⼀种⼤致的平衡，不严格保证左右⼦树的⾼度差不超过 1。这导致节点数相同的情况下，红⿊树的⾼度可能更⾼，也就是说平均查找次数会⾼于相同情况的 AVL 树。

在插⼊时，红⿊树和 AVL 树都能在⾄多两次旋转内恢复平衡，在删除时由于红⿊树只追求⼤致平衡，因此红⿊树⾄多三次旋转可以恢复平衡，⽽ AVL 树最多需要 O(logn) 次。AVL 树在插⼊和删除时，将向上回溯确定是否需要旋转，这个回溯的时间成本最差为 O(logn)，⽽红⿊树每次向上回溯的步⻓为 2，回溯成本低。因此⾯对频繁地插⼊与删除红⿊树更加合适。

## Q8：B 树和B+ 树的区别？





![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1662348730557-7fb979a5-1145-42f7-9bbf-3115190b4e24.png)



B 树中每个节点同时存储 key 和 data，⽽ B+ 树中只有叶⼦节点才存储 data，⾮叶⼦节点只存储 key。InnoDB 对 B+ 树进⾏了优化，在每个叶⼦节点上增加了⼀个指向相邻叶⼦节点的链表指针，形成了带有顺序指针的 B+ 树，提⾼区间访问的性能。

B+ 树的优点在于： ① 由于 B+ 树在⾮叶⼦节点上不含数据信息，因此在内存⻚中能够存放更多的key，数据存放得更加紧密，具有更好的空间利⽤率，访问叶⼦节点上关联的数据也具有更好的缓存命 中率。 ② B+树的叶⼦结点都是相连的，因此对整棵树的遍历只需要⼀次线性遍历叶⼦节点即可。⽽ B 树则需要进⾏每⼀层的递归遍历，相邻的元素可能在内存中不相邻，所以缓存命中性没有 B+树好。但是 B 树也有优点，由于每个节点都包含 key 和 value，因此经常访问的元素可能离根节点更近，访问也更迅速。



## [Q9：图](https://www.topgoer.com/Go高级/图.html)



## [Q10：散列表](https://www.topgoer.com/Go高级/散列表.html)



## [Q11：堆](https://www.topgoer.com/Go高级/堆.html)



## [Q12：链表](https://www.topgoer.com/Go高级/链表.html)



## [Q13：跳跃表](https://www.topgoer.com/Go高级/跳跃表.html)



## [Q14：字典树](https://www.topgoer.com/Go高级/字典树.html)



## [Q15：向量空间](https://www.topgoer.com/Go高级/向量空间.html)

# 排序算法

## 排序有哪些分类？

### 1)内部排序

指将需要处理的所有数据都加载到内部存储器(内存)中进行排序。

内部排序包括⽐较排序和⾮⽐较排序，⽐较排序包括插⼊/选择/交换/归并排序，⾮⽐较排序包括计数/ 基数/桶排序。

插⼊排序包括直接插⼊/希尔排序，选择排序包括直接选择/堆排序，交换排序包括冒泡/快速排序。

### 2)外部排序法

数据量过大，无法全部加载到内存中，需要借助外部存储(文件等)进行排序。

### 3）常见的排序算法分类(如图)

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671462941318-12f62558-3b48-4b4d-abb9-adfb806c4428.png)



## 各类算法时间复杂度、空间复杂度、稳定性对比

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671463991125-53080e1c-99d5-4024-8fbb-1e7f44110614.png)

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1662349078869-c2b438c5-6060-4a5f-b811-2188332caee7.png)

**稳定**：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。

**不稳定**：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。

### 时间复杂度：

1.时间复杂度

一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n),使得当n趋近于无穷大时，T（n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=Ｏ(f(n)),称Ｏ(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。

上面这一段解释是很规范的，但是对于非专业性的我们来说并不是那么好理解，说白了时间复杂度就是时间复杂度的计算并不是计算程序具体运行的时间，而是算法执行语句的次数。通常我们计算时间复杂度都是计算最坏情况 。

#### 最好时间复杂度:

在完全有序的情况下的时间复杂度（满有序度）如(1，2，3)

#### 最坏时间复杂度

最好时间复杂度:在完全有序的情况下的时间复杂度（满有序度)如（1，2，3)

#### 平均时间复杂度

平均时间复杂度是指所有可能的输入实例均以等概率出现的情况下，算法的期望运行时间。设每种情况的出现的概率为pi,平均时间复杂度则为sum(pi*f(n))

### 空间复杂度：

一个程序的空间复杂度是指运行完一个程序所需**内存的大小**。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。　　

（1）**固定部分**。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。

（2）**可变空间**，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。

一个算法所需的存储空间用f(n)表示。S(n)=O(f(n))　　其中n为问题的规模，S(n)表示空间复杂度。 

### 稳定性：

如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671463906873-1d75eacb-da8f-43f7-92d0-b4d474d965e6.png)

稳定也可以理解为一切皆在掌握中,元素的位置处在你在控制中.而不稳定算法有时就有点碰运气,随机的成分.当两元素相等时它们的位置在排序后可能仍然相同.但也可能不同.是未可知的.

另外要注意的是:算法思想的本身是独立于编程语言的,所以你写代码去实现算法的时候很多细节可以做不同的处理.采用不稳定算法不管你具体实现时怎么写代码,最终相同元素位置总是不确定的(可能位置没变也可能变了).而稳定排序算法是你在具体实现时如果细节方面处理的好就会是稳定的,但有些细节没处理得到的结果仍然是不稳定的.

比如冒泡排序,直接插入排序,归并排序虽然是稳定排序算法,但如果你实现时细节没处理好得出的结果也是不稳定的.

### 稳定性的用处

我们平时自己在使用排序算法时用的测试数据就是简单的一些数值本身.没有任何关联信息.这在实际应用中一般没太多用处.实际应该中肯定是排序的数值关联到了其他信息,比如数据库中一个表的主键排序,主键是有关联到其他信息.另外比如对英语字母排序,英语字母的数值关联到了字母这个有意义的信息.

可能大部分时候我们不用考虑算法的稳定性.两个元素相等位置是前是后不重要.但有些时候稳定性确实有用处.它体现了程序的健壮性.比如你网站上针对最热门的文章或啥音乐电影之类的进行排名.由于这里排名不会像我们成绩排名会有并列第几名之说.所以出现了元素相等时也会有先后之分.如果添加进新的元素之后又要重新排名了.之前并列名次的最好是依然保持先后顺序才比较好.

## [冒泡排序](https://www.topgoer.com/Go高级/冒泡排序算法.html)

稳定，平均/最坏时间复杂度 O(n²)，元素基本有序时最好时间复杂度 O(n)，空间复杂度 O(1)。

⽐较相邻的元素，如果第⼀个⽐第⼆个⼤就进⾏交换，对每⼀对相邻元素做同样的⼯作，从开始第⼀对 到结尾的最后⼀对，每⼀轮排序后末尾元素都是有序的，针对 n 个元素重复以上步骤 n -1 次排序完毕。

当序列已经有序时仍会进⾏不必要的⽐较，可以设置⼀个标志记录是否有元素交换，如果没有直接结束⽐较。

### 思想：

冒泡排序(Bubble Sorting）的基本思想是:通过对待排序序列从后向前（从下标较大的元素开始）﹐依次比较相邻元素的排序码，若发现逆序则交换，使排序码较小的元素逐渐从后部移向前部（从下标较大的单元移向下标较小的单元），就象水底下的气泡一样逐渐向上冒。

**因为排序的过程中，各元素不断接近自己的位置，如果一趟比较下来没有进行过交换,就说明序列有序，因此要在排序过程中设置一个标志flag判断元素是否进行过交换。从而减少不必要的比较。**



### 实现

算法描述：冒泡算法，数组中前一个元素和后一个元素进行比较如果大于或者小于 前者就进行交换，最终返回最大或者最小都冒到数组的最后序列时间复杂度为 **O(n^2)**.

#### 算法步骤

- 从数组开头选择相邻两个元素进行比较，并进行交换
- 不停向后移动

```go
package sort

import "fmt"

//冒泡排序
func main() {
    arr := []int{1, 9, 10, 30, 2, 5, 45, 8, 63, 234, 12}
    fmt.Println(GetMax(arr))
    fmt.Println(BubbleSort(arr))
}

//冒泡排序获取最大值
func GetMax(arr []int) int {
    for j := 1; j < len(arr); j++ {
        if arr[j-1] > arr[j] {
            arr[j-1], arr[j] = arr[j], arr[j-1]
        }
    }
    return arr[len(arr)-1]
}

//冒泡排序
func BubbleSort(arr []int) []int {
    for i := 0; i < len(arr); i++ {
        for j := i + 1; j < len(arr); j++ {
            if arr[i] > arr[j] {
                arr[i], arr[j] = arr[j], arr[i]
            }
        }
    }
    return arr
}
```

## [选择排序](https://www.topgoer.cn/docs/goalgorithm/goalgorithm-1cm6att75q48j)

### 基本介绍

选择式排序也属于内部排序法，是从欲排序的数据中，按指定的规则选出某一元素，经过和其他元素重整，再依原则交换位置后达到排序的目的。

**其实选择排序是非常简单的，和冒泡排序有异曲同工之妙。就是把元素分成两部分，一部分是有序的，另外一部分是无序的；每次循环从无序的元素中选取一个元素放到有序的元素中，依次循环到最后把所有元素都放到了有序那一部分中（也就是无序部分，元素为零）；**

### 思想：

选择排序（select sorting）也是一种简单的排序方法。它的**基本思想**是:

1. 第一次从R[0]~R[n-1]中选取最小值，与R[0]交换，
2. 第二次从R[1]~R[n-1]中选取最小值，与R[1]交换，
3. 第三次从R[2]~R[n-1]中选取最小值，与R[2]交换，…，
4. 第i次从R[i-1]~R[n-1]中选取最小值，与R[-1]交换，…，
5. 第n-1次从R[n-2]~R[n-1]中选取最小值，与R[n-2]交换，
6. 总共通过n-1次，得到一个按排序码从小到大排列的有序序列。

### 算法描述

**描述一：**

1. 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置
2. 从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。
3. 重复第二步，直到所有元素均排序完毕。

**描述二：**

1、外循环：循环每个位置（其实就是选择了这个位置，然后用内循环去选择一个合适的数，放到这个位置）；

2、内循环：在无序元素中选择一个合适的数；

3、把第二步选中的数据放到第一步选中的位置上就可以了；

### 选择排序思路分析图

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671459717188-c9be4e71-801e-4e76-af3a-f2a9d5d1b42b.png)

### 代码实现

```go
package main

import (
	"fmt"
)

//SelectSort 选择排序
// 最好、最坏、平均时间复杂度均为：O(n^2),
// 空间复杂度:O(1)
// 稳定性：不稳定 如:5 5 2
func SelectSort(arr []int) []int {
	//1. 先完成将第一个最大值和 arr[0] => 先易后难
	//1 假设  arr[0] 最大值
	for j := 0; j < len(arr)-1; j++ {

		max := arr[j]
		maxIndex := j
		//2. 遍历后面 1---[len(arr) -1] 比较
		for i := j + 1; i < len(arr); i++ {
			if max < arr[i] { //找到真正的最大值
				max = arr[i]
				maxIndex = i
			}
		}
		//交换
		if maxIndex != j {
			arr[j], arr[maxIndex] = arr[maxIndex], arr[j]
		}
		fmt.Printf("第%d次 %v\n  ", j+1, arr)
	}
	return arr
}

func main() {
	//定义一个数组
	arr := []int{10, 34, 19, 100, 80, 789}
	selectSort := SelectSort(arr)
	fmt.Println(selectSort)
}

/**
第1次 [789 34 19 100 80 10]
  第2次 [789 100 19 34 80 10]
  第3次 [789 100 80 34 19 10]
  第4次 [789 100 80 34 19 10]
  第5次 [789 100 80 34 19 10]
  [789 100 80 34 19 10] 
*/
```

### 复杂度

#### 时间复杂度

可以很直观的看出选择排序的时间复杂度：就是两个循环消耗的时间；

- 第一次内循环比较N - 1次，然后是N-2次，N-3次，……，最后一次内循环比较1次。共比较的次数是 (N - 1) + (N - 2) + ... + 1，求等差数列和，得 (N - 1 + 1)* N / 2 = N^2 / 2。舍去最高项系数，其时间复杂度为 O(N^2)。
- 所以**最优**的时间复杂度  和**最差**的时间复杂度   和**平均**时间复杂度  都为 ：**O(n^2)**

#### 空间复杂度，

- 最优的情况下（已经有顺序）复杂度为：O(0) ；
- 最差的情况下（全部元素都要重新排序）复杂度为：O(n );
- 平均的时间复杂度：O(1)

### 稳定性

选择排序是一个不稳定的排序算法，比如数组：[5 6 5 1]，第一轮迭代时最小的数是 1，那么与第一个元素 5 交换位置，这样数字 1 就和数字 5 交换了位置，导致两个相同的数字 5 排序后位置变了。

### 适用场景

选择排序实现也比较简单，并且由于在各种情况下复杂度波动小，因此一般是优于冒泡排序的。在所有的完全交换排序中，选择排序也是比较不错的一种算法。但是，由于固有的O(n2)复杂度，选择排序在海量数据面前显得力不从心。因此，它适用于简单数据排序。

------

## [插入排序](https://www.topgoer.cn/docs/goalgorithm/goalgorithm-1cm6avesshjb1)



### 基本介绍

插入式排序属于内部排序法，是对于欲排序的元素以插入的方式找寻该元素的适当位置，以达到排序的目的。

### 思想

插入排序（Insertion Sorting)的**基本思想**是:

1. 把n个待排序的元素看成为一个有序表和一个无序表
2. 开始时有序表中只包含一个元素，无序表中包含有n-1个元素
3. 排序过程中每次从无序表中取出第一个元素，把它的排序码依次与有序表元素的排序码进行比较，将它插入到有序表中的适当位置，使之成为新的有序表。

### 算法描述

1. 把待排序的数组分成已排序和未排序两部分，初始的时候把第一个元素认为是已排好序的。
2. 从第二个元素开始，在已排好序的子数组中寻找到该元素合适的位置并插入该位置。
3. 重复上述过程直到最后一个元素被插入有序子数组中。

### 思路分析图

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671528532861-7cf60c5c-e9f0-4eea-94e3-1bdd20553911.png)

### 代码实现

```go
package main

import (
	"fmt"
)

// InsertSort 插入排序
// 平均时间复杂度o(n^2)
// 最好时间复杂度o(n)
// 空间复杂度o(1)
// 稳定
func InsertSort(arr []int) []int {

	//完成第一次，给第二个元素找到合适的位置并插入
	for i := 1; i < len(arr); i++ {

		insertVal := arr[i]
		insertIndex := i - 1 // 下标

		//从大到小
		for insertIndex >= 0 && arr[insertIndex] < insertVal {
			arr[insertIndex+1] = arr[insertIndex] // 数据后移
			insertIndex--
		}
		//插入
		if insertIndex+1 != i {
			arr[insertIndex+1] = insertVal
		}
		fmt.Printf("第%d次插入后 %v\n", i, arr)
	}
	return arr
}
func main() {
	arr := []int{23, 0, 12, 56, 34, -1, 55}
	insertSort := InsertSort(arr)
	fmt.Println(insertSort)
}

/**
第1次插入后 [23 0 12 56 34 -1 55]
第2次插入后 [23 12 0 56 34 -1 55]
第3次插入后 [56 23 12 0 34 -1 55]
第4次插入后 [56 34 23 12 0 -1 55]
第5次插入后 [56 34 23 12 0 -1 55]
第6次插入后 [56 55 34 23 12 0 -1]
[56 55 34 23 12 0 -1]
*/
```

### 复杂度

#### 时间复杂度

1. **平均：**时间复杂度 O(n²)
2. **最坏：**插入排序的时间复杂度分析。在最坏情况下，数组完全逆序，插入第2个元素时要考察前1个元素，插入第3个元素时，要考虑前2个元素，……，插入第N个元素，要考虑前 N - 1 个元素。因此，最坏情况下的比较次数是 1 + 2 + 3 + ... + (N - 1)，等差数列求和，结果为 N^2 / 2，所以最坏情况下的复杂度为 O(N^2)。
3. **最好**：最坏情况下，数组已经是有序的，每插入一个元素，只需要考查前一个元素，因此最好情况下，插入排序的时间复杂度为O(N)

#### 空间复杂度

只使用了i,insertIndex,insertVal这两个辅助元素，与问题规模无关，空间复杂度为O(1)

### 稳定性

因为是从右到左，将一个个未排序的数，插入到左边已排好序的队列中，所以插入排序，相同的数在排序后顺序不会变化，这个排序算法是稳定的。

### 适用场景

插入排序由于O( n2 )的复杂度，在数组较大的时候不适用。但是，在数据比较少的时候，是一个不错的选择，一般做为快速排序的扩充。

1. 数组规模 n 较小的大多数情况下，我们可以使用插入排序，它比冒泡排序，选择排序都快，甚至比任何的排序算法都快。
2. 数列中的有序性越高，插入排序的性能越高，因为待排序数组有序性越高，插入排序比较的次数越少。
3. 大家都很少使用冒泡、直接选择，直接插入排序算法，因为在有大量元素的无序数列下，这些算法的效率都很低。

## [快速排序](https://www.topgoer.cn/docs/goalgorithm/goalgorithm-1cm6b09u217l1#gcrdaw)

### 基本介绍

快速排序是对冒泡排序的一种改进，也属于交换类的排序算法。

快速排序是一个知名度极高的排序算法，其对于大数据的优秀排序性能和相同复杂度算法中相对简单的实现使它注定得到比其他算法更多的宠爱。

### 思想

**基本思想**是:

1. 通过一趟排序将要排序的数据分割成独立的两部分
2. 其中一部分的所有数据都比另外一部分的所有数据都要小
3. 然后再按此方法对这两部分数据分别进行快速排序
4. 整个排序过程可以递归进行，以此达到整个数据变成有序序列

### 算法描述

1）选择一个基准元素,通常选择第一个元素或者最后一个元素,

2）通过一趟排序将待排序的记录分割成独立的两部分，其中一部分记录的元素值均比基准元素值小。另一部分记录的元素值比基准值大。

3）此时基准元素在其排好序后的正确位置

4）然后分别对这两部分记录用同样的方法继续进行排序，直到整个序列有序。

### 思路分析图

![img](https://cdn.nlark.com/yuque/0/2022/png/22219483/1671617260129-411cb545-9f27-44d3-a77e-e36d98258d22.png)

### 代码实现



### 复杂度

#### 时间复杂度

在最好情况下，每一轮都能平均切分，这样遍历元素只要 n/2 次就可以把数列分成两部分，每一轮的时间复杂度都是：O(n)。因为问题规模每次被折半，折半的数列继续递归进行切分，也就是总的时间复杂度计算公式为： T(n) = 2*T(n/2) + O(n)。按照主定理公式计算，我们可以知道时间复杂度为：O(nlogn)，当然我们可以来具体计算一下：

```go
我们来分析最好情况，每次切分遍历元素的次数为 n/2

T(n) = 2*T(n/2) + n/2
T(n/2) = 2*T(n/4) + n/4
T(n/4) = 2*T(n/8) + n/8
T(n/8) = 2*T(n/16) + n/16
...
T(4) = 2*T(2) + 4
T(2) = 2*T(1) + 2
T(1) = 1

进行合并也就是：

T(n) = 2*T(n/2) + n/2
     = 2^2*T(n/4)+ n/2 + n/2
     = 2^3*T(n/8) + n/2 + n/2 + n/2
     = 2^4*T(n/16) + n/2 + n/2 + n/2 + n/2
     = ...
     = 2^logn*T(1) + logn * n/2
     = 2^logn + 1/2*nlogn
     = n + 1/2*nlogn

因为当问题规模 n 趋于无穷大时 nlogn 比 n 大，所以 T(n) = O(nlogn)。

最好时间复杂度为：O(nlogn)。
```

最差的情况下，每次都不能平均地切分，每次切分都因为基准数是最大的或者最小的，不能分成两个数列，这样时间复杂度变为了 T(n) = T(n-1) + O(n)，按照主定理计算可以知道时间复杂度为：O(n^2)，我们可以来实际计算一下：

```go
我们来分析最差情况，每次切分遍历元素的次数为 n

T(n) = T(n-1) + n
     = T(n-2) + n-1 + n
     = T(n-3) + n-2 + n-1 + n
     = ...
     = T(1) + 2 +3 + ... + n-2 + n-1 + n
     = O(n^2)

最差时间复杂度为：O(n^2)。
```

根据熵的概念，数量越大，随机性越高，越自发无序，所以待排序数据规模非常大时，出现最差情况的情形较少。在综合情况下，快速排序的平均时间复杂度为：O(nlogn)。对比之前介绍的排序算法，快速排序比那些动不动就是平方级别的初级排序算法更佳。

#### 优化

切分的结果极大地影响快速排序的性能，为了避免切分不均匀情况的发生，有几种方法改进：

1. 每次进行快速排序切分时，先将数列随机打乱，再进行切分，这样随机加了个震荡，减少不均匀的情况。当然，也可以随机选择一个基准数，而不是选第一个数。
2. 每次取数列头部，中部，尾部三个数，取三个数的中位数为基准数进行切分。

方法 1 相对好，而方法 2 引入了额外的比较操作，一般情况下我们可以随机选择一个基准数。

#### 空间复杂度

快速排序使用原地排序，存储空间复杂度为：O(1)。而因为递归栈的影响，递归的程序栈开辟的层数范围在 logn~n，所以递归栈的空间复杂度为：O(logn)~log(n)，最坏为：log(n)，当元素较多时，程序栈可能溢出。通过改进算法，使用伪尾递归进行优化，递归栈的空间复杂度可以减小到 O(logn)，可以见下面算法优化。

### 稳定性

快速排序是不稳定的，因为切分过程中进行了交换，相同值的元素可能发生位置变化。

### 使用场景

快速排序在大多数情况下都是适用的，尤其在数据量大的时候性能优越性更加明显。但是在必要的时候，需要考虑下优化以提高其在最坏情况下的性能。

### 补充：内置库使用快速排序的原因

首先堆排序，归并排序最好最坏时间复杂度都是：O(nlogn)，而快速排序最坏的时间复杂度是：O(n^2)，但是很多编程语言内置的排序算法使用的仍然是快速排序，这是为什么？

1. 这个问题有偏颇，选择排序算法要看具体的场景，Linux 内核用的排序算法就是堆排序，而 Java 对于数量比较多的复杂对象排序，内置排序使用的是归并排序，只是一般情况下，快速排序更快。
2. 归并排序有两个稳定，第一个稳定是排序前后相同的元素位置不变，第二个稳定是，每次都是很平均地进行排序，读取数据也是顺序读取，能够利用存储器缓存的特征，比如从磁盘读取数据进行排序。因为排序过程需要占用额外的辅助数组空间，所以这部分有代价损耗，但是原地手摇的归并排序克服了这个缺陷。
3. 复杂度中，大 O 有一个常数项被省略了，堆排序每次取最大的值之后，都需要进行节点翻转，重新恢复堆的特征，做了大量无用功，常数项比快速排序大，大部分情况下比快速排序慢很多。但是堆排序时间较稳定，不会出现快排最坏 O(n^2) 的情况，且省空间，不需要额外的存储空间和栈空间。
4. 当待排序数量大于16000个元素时，使用自底向上的堆排序比快速排序还快，可见此：https://core.ac.uk/download/pdf/82350265.pdf。
5. 快速排序最坏情况下复杂度高，主要在于切分不像归并排序一样平均，而是很依赖基准数的现在，我们通过改进，比如随机数，三切分等，这种最坏情况的概率极大的降低。大多数情况下，它并不会那么地坏，大多数快才是真的块。
6. 归并排序和快速排序都是分治法，排序的数据都是相邻的，而堆排序比较的数可能跨越很大的范围，导致局部性命中率降低，不能利用现代存储器缓存的特征，加载数据过程会损失性能。

对稳定性有要求的，要求排序前后相同元素位置不变，可以使用归并排序，Java 中的复杂对象类型，要求排序前后位置不能发生变化，所以小规模数据下使用了直接插入排序，大规模数据下使用了归并排序。

对栈，存储空间有要求的可以使用堆排序，比如 Linux 内核栈小，快速排序占用程序栈太大了，使用快速排序可能栈溢出，所以使用了堆排序。



## Q11：希尔排序的原理？

⼜称缩⼩增量排序，是对直接插⼊排序的改进，不稳定，平均时间复杂度 O(n^1.3^)，最差时间复杂度O(n²)，最好时间复杂度 O(n)，空间复杂度 O(1)。

把记录按下标的⼀定增量分组，对每组进⾏直接插⼊排序，每次排序后减⼩增量，当增量减⾄ 1 时排序完毕。

## Q13：[堆排序的原理及实现](https://www.topgoer.com/Go高级/堆排序算法.html)？

### 原理

是对直接选择排序的改进，不稳定，时间复杂度 O(nlogn)，空间复杂度 O(1)。

将待排序记录看作完全⼆叉树，可以建⽴⼤根堆或⼩根堆，⼤根堆中每个节点的值都不⼩于它的⼦节点 值，⼩根堆中每个节点的值都不⼤于它的⼦节点值。

以⼤根堆为例，在建堆时⾸先将最后⼀个节点作为当前节点，如果当前节点存在⽗节点且值⼤于⽗节点，就将当前节点和⽗节点交换。在移除时⾸先暂存根节点的值，然后⽤最后⼀个节点代替根节点并作 为当前节点，如果当前节点存在⼦节点且值⼩于⼦节点，就将其与值较⼤的⼦节点进⾏交换，调整完堆 后返回暂存的值。



### 实现

算法描述：首先建一个堆，然后调整堆，调整过程是将节点和子节点进行比较，将 其中最大的值变为父节点，递归调整调整次数lgn,最后将根节点和尾节点交换再n次 调整**O(nlgn)**.

#### 算法步骤

- 创建最大堆或者最小堆（我是最小堆）
- 调整堆
- 交换首尾节点(为了维持一个完全二叉树才要进行收尾交换)

```go
package sort

import "fmt"

//堆排序
func main() {
    arr := []int{1, 9, 10, 30, 2, 5, 45, 8, 63, 234, 12}
    fmt.Println(HeapSort(arr))
}
func HeapSortMax(arr []int, length int) []int {
    // length := len(arr)
    if length <= 1 {
        return arr
    }
    depth := length/2 - 1 //二叉树深度
    for i := depth; i >= 0; i-- {
        topmax := i //假定最大的位置就在i的位置
        leftchild := 2*i + 1
        rightchild := 2*i + 2
        if leftchild <= length-1 && arr[leftchild] > arr[topmax] { //防止越过界限
            topmax = leftchild
        }
        if rightchild <= length-1 && arr[rightchild] > arr[topmax] { //防止越过界限
            topmax = rightchild
        }
        if topmax != i {
            arr[i], arr[topmax] = arr[topmax], arr[i]
        }
    }
    return arr
}
func HeapSort(arr []int) []int {
    length := len(arr)
    for i := 0; i < length; i++ {
        lastlen := length - i
        HeapSortMax(arr, lastlen)
        if i < length {
            arr[0], arr[lastlen-1] = arr[lastlen-1], arr[0]
        }
    }
    return arr
}
```

## Q16：[基数排序算法](https://www.topgoer.com/Go高级/基数排序算法.html)



算法描述：基数排序类似计数排序，需要额外的空间来记录对应的基数内的数据 额外的空间是有序的，最终时间复杂度**O(nlogrm)**,r是基数，r^m=n.当给定 特定的范围，计数排序又可以叫桶排序，当以10进制为基数时就是简单的桶排序

#### 算法步骤

- 从个位开始排序，从低到高进行递推
- 比较过程中如果遇到高位相同时，顺序不变

#### 算法分两类

1. 低位排序LSD
2. 高位排序MSD

```go
package sort

import "fmt"

func main() {
    var arr [3][]int
    myarr := []int{1, 2, 3, 1, 1, 2, 2, 2, 2, 2, 3}
    for i := 0; i < len(myarr); i++ {
        arr[myarr[i]-1] = append(arr[myarr[i]-1], myarr[i])
    }
    fmt.Println(arr)
}
```

## Q16：[拓扑排序](https://www.topgoer.com/Go高级/拓扑排序.html)

####  定义

对于一些有前后依赖关系的排序算法，是利用有向无环图进行实现，通过局部依赖关系确定全局顺序的算法

#### 应用场景

- 编译有序依赖的文件

### 1.1.1. 两种拓扑算法

#### Kahn算法

- 算法逻辑
- 利用贪心算法，如果两个顶点，顶点b依赖于顶点a,就将a指向b,当一个顶点的入度为零，将这个顶点就是最优排序点， 并且将顶点从图中移除，将可达顶点的入度减一。

#### DFS算法

1.使用深度算法，产生逆向邻接表先输出其他依赖，最后输出自己。

```go
package main

import (
    "fmt"
)

//有向图
type graph struct {
    vertex int           //顶点
    list   map[int][]int //连接表边
}

//添加边
func (g *graph) addVertex(t int, s int) {
    g.list[t] = push(g.list[t], s)
}

func main() {
    g := NewGraph(8)
    g.addVertex(2, 1)
    g.addVertex(3, 1)
    g.addVertex(7, 1)
    g.addVertex(4, 2)
    g.addVertex(5, 2)
    g.addVertex(8, 7)
    g.DfsSort()
}

//创建图
func NewGraph(v int) *graph {
    g := new(graph)
    g.vertex = v
    g.list = map[int][]int{}
    i := 0
    for i < v {
        g.list[i] = make([]int, 0)
        i++
    }
    return g
}

//取出切片第一个
func pop(list []int) (int, []int) {
    if len(list) > 0 {
        a := list[0]
        b := list[1:]
        return a, b
    } else {
        return -1, list
    }
}

//推入切片
func push(list []int, value int) []int {
    result := append(list, value)
    return result
}

//添加边
func (g *graph) KhanSort() {
    var inDegree = make(map[int]int)
    var queue []int
    for i := 1; i <= g.vertex; i++ {
        for _, m := range g.list[i] {
            inDegree[m]++
        }
    }
    for i := 1; i <= g.vertex; i++ {

        if inDegree[i] == 0 {
            queue = push(queue, i)
        }
    }
    for len(queue) > 0 {
        var now int
        now, queue = pop(queue)
        fmt.Println("->", now)
        for _, k := range g.list[now] {
            inDegree[k]--
            if inDegree[k] == 0 {
                queue = push(queue, k)
            }
        }
    }
}

func (g *graph) DfsSort() {
    inverseList := make(map[int][]int)
    //初始化逆向邻接表
    for i := 1; i <= g.vertex; i++ {
        for _, k := range g.list[i] {
            inverseList[k] = append(inverseList[k], i)
        }
    }
    visited := make([]bool, g.vertex+1)
    visited[0] = true
    for i := 1; i <= g.vertex; i++ {
        if visited[i] == false {
            visited[i] = true
            dfs(i, inverseList, visited)
        }
    }

}

func dfs(vertex int, inverseList map[int][]int, visited []bool) {
    for _, w := range inverseList[vertex] {
        if visited[w] == true {
            continue
        } else {
            visited[w] = true
            dfs(w, inverseList, visited)
        }
    }
    fmt.Println("->", vertex)
}
```

## Q16：循环和递归，你说下有什么不同的点？



递归算法：

优点：代码少、简介。

缺点：它的运行需要较多次数的函数调用，如果调用层数比较深，需要增加额外的堆栈处理，比如参数传递需要压栈等操作，会对执行效率有一定影响。但是，对于某些问题，如果不使用递归，那将是极端难看的代码。

循环算法：

优点：速度快，结构简单。

缺点：并不能解决所有的问题。有的问题适合使用递归而不是循环。如果使用循环并不困难的话，最好使用循环。

## Q17：排序算法怎么选择？

数据量规模较⼩，考虑直接插⼊或直接选择。当元素分布有序时直接插⼊将⼤⼤减少⽐较和移动记录的次数，如果不要求稳定性，可以使⽤直接选择，效率略⾼于直接插⼊。

数据量规模中等，选择希尔排序。

数据量规模较⼤，考虑堆排序（元素分布接近正序或逆序）、快速排序（元素分布随机）和归并排序稳定性）。⼀般不使⽤冒泡。

数据分布比较均匀，桶排序。



# 查找

## [二分查找](https://www.topgoer.com/Go高级/二分查找方法.html) 

算法描述：在一组有序数组中，将数组一分为二，将要查询的元素和分割点进行比较，分为三种情况

- 相等直接返回
- 元素大于分割点，在分割点右侧继续查找
- 元素小于分割点，在分割点左侧继续查找

时间复杂： **O(lgn)**.

#### 要求

- 必须是有序的数组，并能支持随机访问

#### 变形

- 查找第一个值等于给定的

- - 在相等的时候做处理，向前查

- 查找最后一个值等于给定的值

- - 在相等的时候做处理，向后查

- 查找第一个大于等于给定的值

- - 判断边界减1

- 查找最后一个小于等于给定的值

- - 判断边界加1

#### 实际应用

- 用户ip区间段查询
- 用于相似度查询



```go
package sort

import "fmt"

func bin_search(arr []int, finddata int) int {
    low := 0
    high := len(arr) - 1
    for low <= high {
        mid := (low + high) / 2
        fmt.Println(mid)
        if arr[mid] > finddata {
            high = mid - 1
        } else if arr[mid] < finddata {
            low = mid + 1
        } else {
            return mid
        }
    }
    return -1
}

func main() {
    arr := make([]int, 1024*1024, 1024*1024)
    for i := 0; i < 1024*1024; i++ {
        arr[i] = i + 1
    }
    id := bin_search(arr, 1024)
    if id != -1 {
        fmt.Println(id, arr[id])
    } else {
        fmt.Println("没有找到数据")
    }
}
```